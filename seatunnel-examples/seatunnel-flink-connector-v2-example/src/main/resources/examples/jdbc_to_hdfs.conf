env {
    execution.parallelism = 1
    _flink.classloader.check-leaked-classloader = false
    execution.planner = blink
    job.mode = BATCH
}

source {
    Jdbc {
        datasource = "zt17606_test_mysql"
        fetchSize = 1024
        tables = "test_stream_binlog.trackingorderdetails"
        auto_partition = "true"
        result_table_name = "s1"
    }
}

transform {
}

sink {
    HdfsFile {
        fs.defaultFS = "hdfs://zthdp"
        path = "/user/zt17606/hudi/test_stream_binlog.db/trackingorderdetails"
        hdfs_site_path = "D:/soft/hadoop/etc-uat/hdfs-site.xml"
        file_name_expression  = "【test】-【${transactionId}】-【${uuid}】-【${now}】"
        file_format = "parquet"
        partition_by = ["OrderId"]
        partition_dir_expression = "${k0}=${v0}"
    }
    HdfsFile {
        fs.defaultFS = "hdfs://zthdp"
        path = "/user/zt17606/hudi/test_stream_binlog.db/trackingorderdetails"
        hdfs_site_path = "D:/soft/hadoop/etc-uat/hdfs-site.xml"
        file_name_expression  = "【test】-【${transactionId}】-【${uuid}】-【${now}】"
        file_format = "text"
        field_delimiter = ","
        partition_by = ["OrderId"]
        partition_dir_expression = "${k0}=${v0}"
    }
}